{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:09:23.029221Z",
     "start_time": "2025-09-19T14:09:23.019891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Dict, Tuple, Set\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np"
   ],
   "id": "e1621afdae3e0506",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:09:23.367543Z",
     "start_time": "2025-09-19T14:09:23.349771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_counts(text: List) -> Tuple[List[List[str]], Set[str], int, Dict[str, int]]:\n",
    "    sentences = []; word_set = []\n",
    "\n",
    "    for sent in text:\n",
    "        x = [i.lower() for i in word_tokenize(sent) if i.isalpha()]\n",
    "\n",
    "        sentences.append(x)\n",
    "        for word in x:\n",
    "            word_set.append(word)\n",
    "\n",
    "    word_set = set(word_set)\n",
    "    total_documents = len(sentences)\n",
    "\n",
    "    index_dict = {}\n",
    "    i = 0\n",
    "    for word in word_set:\n",
    "        index_dict[word] = i\n",
    "        i += 1\n",
    "    return sentences, word_set, total_documents, index_dict"
   ],
   "id": "674d117c7121d7e2",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:09:23.826745Z",
     "start_time": "2025-09-19T14:09:23.816583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def word_document_frequency(sentences: List, word_set: set) -> set:\n",
    "    word_count = {}\n",
    "    for word in word_set:\n",
    "        word_count[word] = 0\n",
    "        for sent in sentences:\n",
    "            if word in sent:\n",
    "                word_count[word] += 1\n",
    "    return word_count"
   ],
   "id": "1245e6b9602eb0a6",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:09:24.206657Z",
     "start_time": "2025-09-19T14:09:24.200803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def term_freq(word: str, document: List) -> float:\n",
    "    return document.count(word) / len(document)"
   ],
   "id": "3dda8c3a8b91f407",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:09:24.650111Z",
     "start_time": "2025-09-19T14:09:24.645898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def inversed_term_freq(word: str, n: int, wdf: Dict) -> float:\n",
    "    return np.log(n / wdf.get(word, 0) + 1)"
   ],
   "id": "8895fdafb946864",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:09:25.089429Z",
     "start_time": "2025-09-19T14:09:25.084670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tf_idf(\n",
    "        sentence: List,\n",
    "        index_dict: Dict,\n",
    "        total_documents: int,\n",
    "        wdf: Dict,\n",
    "        vector_shape: int\n",
    "    ) -> np.array:\n",
    "    tf_idf_vec = np.zeros((vector_shape, ))\n",
    "\n",
    "    for word in sentence:\n",
    "        tf = term_freq(word, sentence)\n",
    "        idf = inversed_term_freq(word, total_documents, wdf)\n",
    "        tf_idf_vec[index_dict[word]] = tf * idf\n",
    "\n",
    "    return tf_idf_vec"
   ],
   "id": "f0fa60e68b1c9ea3",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T14:09:25.622133Z",
     "start_time": "2025-09-19T14:09:25.608764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tf_idf_vectors(text: List) -> np.array:\n",
    "    vectors = []\n",
    "\n",
    "    sentences, word_set, total_documents, index_dict = create_counts(text)\n",
    "    wdf = word_document_frequency(sentences, word_set)\n",
    "    vector_shape = len(word_set)\n",
    "\n",
    "    for sent in sentences:\n",
    "        vec = tf_idf(sent, index_dict, total_documents, wdf, vector_shape)\n",
    "        vectors.append(vec)\n",
    "        # vectors = np.array(vectors)\n",
    "\n",
    "    return np.array(vectors)"
   ],
   "id": "1a12b3bb59f8850d",
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-19T14:09:26.055915Z",
     "start_time": "2025-09-19T14:09:26.049903Z"
    }
   },
   "source": [
    "text = [\n",
    "    'This is the first document this.',\n",
    "    'This one is the second one.',\n",
    "    'And this is the third.',\n",
    "    'Is it the first document?'\n",
    "]\n",
    "\n",
    "vectors = tf_idf_vectors(text)"
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf6eedb94dd370cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
